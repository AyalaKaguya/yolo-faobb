{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41676bce",
   "metadata": {},
   "source": [
    "# 修改 YOLO 框架使其支持全角度\n",
    "\n",
    "**注意：**这个修改对于本项目**不是必须**的，只是提供一个思路尝试让原版YOLO-OBB模型支持全角度预测。\n",
    "\n",
    "**Note:** This modification is **not** required for this project. It just provides an idea to try to make the original YOLO-OBB model support full-angle prediction.\n",
    "\n",
    "如果你想使用此**一阶段模型**实现全角度预测，你需要注意：\n",
    "- 即使经过以下修改，模型依旧也只能预测0°~180°，无法实现全角度预测。\n",
    "- 对于输出角向量的方案，简单的修改下，模型完全无法正常收敛，需要修改整个输出头和损失计算过程。\n",
    "- 本项目仅限工程上主观验证，欢迎进行更加量化、更加系统的验证。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1233ce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from ultralytics.utils.loss import v8DetectionLoss, RotatedBboxLoss\n",
    "from ultralytics.utils.tal import RotatedTaskAlignedAssigner, make_anchors\n",
    "from ultralytics.nn.modules import Detect, Conv\n",
    "from ultralytics.utils.tal import dist2rbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331ca9e5",
   "metadata": {},
   "source": [
    "utils/ops.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e75899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyxyxyxy2xywhr_old(x):\n",
    "    \"\"\"\n",
    "    Convert batched Oriented Bounding Boxes (OBB) from [xy1, xy2, xy3, xy4] to [xywh, rotation] format.\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray | torch.Tensor): Input box corners with shape (N, 8) in [xy1, xy2, xy3, xy4] format.\n",
    "\n",
    "    Returns:\n",
    "        (np.ndarray | torch.Tensor): Converted data in [cx, cy, w, h, rotation] format with shape (N, 5).\n",
    "            Rotation values are in radians from 0 to pi/2.\n",
    "    \"\"\"\n",
    "    is_torch = isinstance(x, torch.Tensor)\n",
    "    points = x.cpu().numpy() if is_torch else x\n",
    "    points = points.reshape(len(x), -1, 2)\n",
    "    rboxes = []\n",
    "    for pts in points:\n",
    "        # NOTE: Use cv2.minAreaRect to get accurate xywhr,\n",
    "        # especially some objects are cut off by augmentations in dataloader.\n",
    "        (cx, cy), (w, h), angle = cv2.minAreaRect(pts)\n",
    "        rboxes.append([cx, cy, w, h, angle / 180 * np.pi])\n",
    "    return torch.tensor(rboxes, device=x.device, dtype=x.dtype) if is_torch else np.asarray(rboxes)\n",
    "\n",
    "\n",
    "def xyxyxyxy2xywhr(x):\n",
    "    \"\"\"\n",
    "    Convert batched Oriented Bounding Boxes (OBB) from [xy1, xy2, xy3, xy4] to [xywh, rotation] format.\n",
    "\n",
    "    四个点按照逆时针顺序排列\n",
    "    1. 规定pt1为右下角, pt2为右上角, pt3为左上角, pt4为左下角，pt1和pt2组成的边是图像的顶部\n",
    "    2. 规定指向图像右侧方向为0°，顺时针方向为正角度，范围在-180°~180°\n",
    "\n",
    "    Args:\n",
    "        x (np.ndarray | torch.Tensor): Input box corners with shape (N, 8) in [xy1, xy2, xy3, xy4] format.\n",
    "\n",
    "    Returns:\n",
    "        (np.ndarray | torch.Tensor): Converted data in [cx, cy, w, h, rotation] format with shape (N, 5).\n",
    "            Rotation values are in radians from -pi to pi.\n",
    "    \"\"\"\n",
    "    is_torch = isinstance(x, torch.Tensor)\n",
    "    points = x.cpu().numpy() if is_torch else x\n",
    "    points = points.reshape(len(x), -1, 2)\n",
    "    rboxes = []\n",
    "    for pts in points:\n",
    "        cx = np.mean(pts[:, 0])\n",
    "        cy = np.mean(pts[:, 1])\n",
    "        pt1, pt2, pt3, pt4 = pts  # 假定检测框都是矩形\n",
    "        w = np.sqrt(np.sum((pt2 - pt3) ** 2))\n",
    "        h = np.sqrt(np.sum((pt4 - pt3) ** 2))\n",
    "        angle = np.arctan2((pt1-pt4)[1], (pt1-pt4)[0])\n",
    "        rboxes.append([cx, cy, w, h, angle])\n",
    "\n",
    "    return torch.tensor(rboxes, device=x.device, dtype=x.dtype) if is_torch else np.asarray(rboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb587950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_segments_old(segments, n: int = 1000):\n",
    "    \"\"\"\n",
    "    Resample segments to n points each using linear interpolation.\n",
    "\n",
    "    Args:\n",
    "        segments (list): List of (N, 2) arrays where N is the number of points in each segment.\n",
    "        n (int): Number of points to resample each segment to.\n",
    "\n",
    "    Returns:\n",
    "        (list): Resampled segments with n points each.\n",
    "    \"\"\"\n",
    "    for i, s in enumerate(segments):\n",
    "        if len(s) == n:\n",
    "            continue\n",
    "        s = np.concatenate((s, s[0:1, :]), axis=0)\n",
    "        x = np.linspace(0, len(s) - 1, n - len(s) if len(s) < n else n)\n",
    "        xp = np.arange(len(s))\n",
    "        x = np.insert(x, np.searchsorted(x, xp), xp) if len(s) < n else x\n",
    "        segments[i] = (\n",
    "            np.concatenate([np.interp(x, xp, s[:, i])\n",
    "                           for i in range(2)], dtype=np.float32).reshape(2, -1).T\n",
    "        )  # segment xy\n",
    "    return segments\n",
    "\n",
    "\n",
    "def resample_segments(segments, n: int = 1000):\n",
    "    \"\"\"\n",
    "    Resample segments to n points each using linear interpolation.\n",
    "\n",
    "    针对OBB的采样将跳过\n",
    "\n",
    "    Args:\n",
    "        segments (list): List of (N, 2) arrays where N is the number of points in each segment.\n",
    "        n (int): Number of points to resample each segment to.\n",
    "\n",
    "    Returns:\n",
    "        (list): Resampled segments with n points each.\n",
    "    \"\"\"\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55b38ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularize_rboxes_old(rboxes):\n",
    "    \"\"\"\n",
    "    Regularize rotated bounding boxes to range [0, pi/2].\n",
    "\n",
    "    Args:\n",
    "        rboxes (torch.Tensor): Input rotated boxes with shape (N, 5) in xywhr format.\n",
    "\n",
    "    Returns:\n",
    "        (torch.Tensor): Regularized rotated boxes.\n",
    "    \"\"\"\n",
    "    x, y, w, h, t = rboxes.unbind(dim=-1)\n",
    "    # Swap edge if t >= pi/2 while not being symmetrically opposite\n",
    "    swap = t % math.pi >= math.pi / 2\n",
    "    w_ = torch.where(swap, h, w)\n",
    "    h_ = torch.where(swap, w, h)\n",
    "    t = t % (math.pi / 2)\n",
    "    return torch.stack([x, y, w_, h_, t], dim=-1)  # regularized boxes\n",
    "\n",
    "\n",
    "def regularize_rboxes(rboxes):\n",
    "    \"\"\"\n",
    "    Regularize rotated bounding boxes to range [0, pi/2].\n",
    "\n",
    "    Args:\n",
    "        rboxes (torch.Tensor): Input rotated boxes with shape (N, 5) in xywhr format.\n",
    "\n",
    "    Returns:\n",
    "        (torch.Tensor): Regularized rotated boxes.\n",
    "    \"\"\"\n",
    "    return rboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b032adf",
   "metadata": {},
   "source": [
    "nn/modules/head.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8ad51a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OBB_old(Detect):\n",
    "    \"\"\"\n",
    "    YOLO OBB detection head for detection with rotation models.\n",
    "\n",
    "    This class extends the Detect head to include oriented bounding box prediction with rotation angles.\n",
    "\n",
    "    Attributes:\n",
    "        ne (int): Number of extra parameters.\n",
    "        cv4 (nn.ModuleList): Convolution layers for angle prediction.\n",
    "        angle (torch.Tensor): Predicted rotation angles.\n",
    "\n",
    "    Methods:\n",
    "        forward: Concatenate and return predicted bounding boxes and class probabilities.\n",
    "        decode_bboxes: Decode rotated bounding boxes.\n",
    "\n",
    "    Examples:\n",
    "        Create an OBB detection head\n",
    "        >>> obb = OBB(nc=80, ne=1, ch=(256, 512, 1024))\n",
    "        >>> x = [torch.randn(1, 256, 80, 80), torch.randn(1, 512, 40, 40), torch.randn(1, 1024, 20, 20)]\n",
    "        >>> outputs = obb(x)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nc: int = 80, ne: int = 1, ch: Tuple = ()):\n",
    "        \"\"\"\n",
    "        Initialize OBB with number of classes `nc` and layer channels `ch`.\n",
    "\n",
    "        Args:\n",
    "            nc (int): Number of classes.\n",
    "            ne (int): Number of extra parameters.\n",
    "            ch (tuple): Tuple of channel sizes from backbone feature maps.\n",
    "        \"\"\"\n",
    "        super().__init__(nc, ch)\n",
    "        self.ne = ne  # number of extra parameters\n",
    "\n",
    "        c4 = max(ch[0] // 4, self.ne)\n",
    "        self.cv4 = nn.ModuleList(nn.Sequential(Conv(x, c4, 3), Conv(\n",
    "            c4, c4, 3), nn.Conv2d(c4, self.ne, 1)) for x in ch)\n",
    "\n",
    "    def forward(self, x: List[torch.Tensor]) -> Union[torch.Tensor, Tuple]:\n",
    "        \"\"\"Concatenate and return predicted bounding boxes and class probabilities.\"\"\"\n",
    "        bs = x[0].shape[0]  # batch size\n",
    "        angle = torch.cat([self.cv4[i](x[i]).view(bs, self.ne, -1)\n",
    "                          for i in range(self.nl)], 2)  # OBB theta logits\n",
    "        # NOTE: set `angle` as an attribute so that `decode_bboxes` could use it.\n",
    "        angle = (angle.sigmoid() - 0.25) * math.pi  # [-pi/4, 3pi/4]\n",
    "        # angle = angle.sigmoid() * math.pi / 2  # [0, pi/2]\n",
    "        if not self.training:\n",
    "            self.angle = angle\n",
    "        x = Detect.forward(self, x)  # type: ignore\n",
    "        if self.training:\n",
    "            return x, angle\n",
    "        if self.export:\n",
    "            return torch.cat([x, angle], 1)  # type: ignore\n",
    "        else:\n",
    "            return torch.cat([x[0], angle], 1), (x[1], angle)\n",
    "\n",
    "    def decode_bboxes(self, bboxes: torch.Tensor, anchors: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Decode rotated bounding boxes.\"\"\"\n",
    "        return dist2rbox(bboxes, self.angle, anchors, dim=1)\n",
    "\n",
    "\n",
    "class OBB(Detect):\n",
    "    \"\"\"\n",
    "    YOLO OBB detection head for detection with rotation models.\n",
    "\n",
    "    This class extends the Detect head to include oriented bounding box prediction with rotation angles.\n",
    "\n",
    "    Attributes:\n",
    "        ne (int): Number of extra parameters.\n",
    "        cv4 (nn.ModuleList): Convolution layers for angle prediction.\n",
    "        angle (torch.Tensor): Predicted rotation angles.\n",
    "\n",
    "    Methods:\n",
    "        forward: Concatenate and return predicted bounding boxes and class probabilities.\n",
    "        decode_bboxes: Decode rotated bounding boxes.\n",
    "\n",
    "    Examples:\n",
    "        Create an OBB detection head\n",
    "        >>> obb = OBB(nc=80, ne=1, ch=(256, 512, 1024))\n",
    "        >>> x = [torch.randn(1, 256, 80, 80), torch.randn(1, 512, 40, 40), torch.randn(1, 1024, 20, 20)]\n",
    "        >>> outputs = obb(x)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nc: int = 80, ne: int = 1, ch: Tuple = ()):\n",
    "        \"\"\"\n",
    "        Initialize OBB with number of classes `nc` and layer channels `ch`.\n",
    "\n",
    "        Args:\n",
    "            nc (int): Number of classes.\n",
    "            ne (int): Number of extra parameters.\n",
    "            ch (tuple): Tuple of channel sizes from backbone feature maps.\n",
    "        \"\"\"\n",
    "        super().__init__(nc, ch)\n",
    "        self.ne = ne  # number of extra parameters\n",
    "\n",
    "        c4 = max(ch[0] // 4, self.ne)\n",
    "        self.cv4 = nn.ModuleList(nn.Sequential(Conv(x, c4, 3), Conv(\n",
    "            c4, c4, 3), nn.Conv2d(c4, self.ne, 1)) for x in ch)\n",
    "\n",
    "    def forward(self, x: List[torch.Tensor]) -> Union[torch.Tensor, Tuple]:\n",
    "        \"\"\"Concatenate and return predicted bounding boxes and class probabilities.\"\"\"\n",
    "        bs = x[0].shape[0]  # batch size\n",
    "        angle = torch.cat([self.cv4[i](x[i]).view(bs, self.ne, -1)\n",
    "                          for i in range(self.nl)], 2)  # OBB theta logits\n",
    "        \n",
    "        # 现在angle由原来的 bs 1 n 变成了 bs 2 n ，我们要将多出来的这一角度提取出来，计算atan2\n",
    "        if self.ne == 2:\n",
    "            # 提取两个角度分量 (sin, cos) 或 (y, x)\n",
    "            angle_y = angle[:, 0:1, :]  # bs, 1, n - y分量或sin分量\n",
    "            angle_x = angle[:, 1:2, :]  # bs, 1, n - x分量或cos分量\n",
    "            \n",
    "            # 使用atan2计算角度，范围在[-π, π]\n",
    "            angle = torch.atan2(angle_y, angle_x)  # bs, 1, n\n",
    "        else:\n",
    "            # 保持原有的角度处理逻辑（兼容性）\n",
    "            # NOTE: set `angle` as an attribute so that `decode_bboxes` could use it.\n",
    "            angle = (angle.sigmoid() - 0.25) * math.pi  # [-pi/4, 3pi/4]\n",
    "            # angle = angle.sigmoid() * math.pi / 2  # [0, pi/2]\n",
    "            # angle = (angle.sigmoid() - 0.5) * math.pi * 2 # [-pi, pi]\n",
    "            # angle = (angle.sigmoid() - 0.75) * math.pi * 4  # [-pi/2, 3pi/2] 即使你缩放了，最后预测的角度也会只收敛到其一半的空间内\n",
    "        if not self.training:\n",
    "            self.angle = angle\n",
    "        x = Detect.forward(self, x)  # type: ignore\n",
    "        if self.training:\n",
    "            return x, angle\n",
    "        if self.export:\n",
    "            return torch.cat([x, angle], 1)  # type: ignore\n",
    "        else:\n",
    "            return torch.cat([x[0], angle], 1), (x[1], angle)\n",
    "\n",
    "    def decode_bboxes(self, bboxes: torch.Tensor, anchors: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Decode rotated bounding boxes.\"\"\"\n",
    "        return dist2rbox(bboxes, self.angle, anchors, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3482b542",
   "metadata": {},
   "source": [
    "utils/loss.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1df42374",
   "metadata": {},
   "outputs": [],
   "source": [
    "class v8OBBLoss_old(v8DetectionLoss):\n",
    "    \"\"\"Calculates losses for object detection, classification, and box distribution in rotated YOLO models.\"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        \"\"\"Initialize v8OBBLoss with model, assigner, and rotated bbox loss; model must be de-paralleled.\"\"\"\n",
    "        super().__init__(model)\n",
    "        self.assigner = RotatedTaskAlignedAssigner(\n",
    "            topk=10, num_classes=self.nc, alpha=0.5, beta=6.0)\n",
    "        self.bbox_loss = RotatedBboxLoss(self.reg_max).to(self.device)\n",
    "\n",
    "    def preprocess(self, targets: torch.Tensor, batch_size: int, scale_tensor: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Preprocess targets for oriented bounding box detection.\"\"\"\n",
    "        if targets.shape[0] == 0:\n",
    "            out = torch.zeros(batch_size, 0, 6, device=self.device)\n",
    "        else:\n",
    "            i = targets[:, 0]  # image index\n",
    "            _, counts = i.unique(return_counts=True)\n",
    "            counts = counts.to(dtype=torch.int32)\n",
    "            out = torch.zeros(batch_size, counts.max(), 6, device=self.device)\n",
    "            for j in range(batch_size):\n",
    "                matches = i == j\n",
    "                if n := matches.sum():\n",
    "                    bboxes = targets[matches, 2:]\n",
    "                    bboxes[..., :4].mul_(scale_tensor)\n",
    "                    out[j, :n] = torch.cat(\n",
    "                        [targets[matches, 1:2], bboxes], dim=-1)\n",
    "        return out\n",
    "\n",
    "    def __call__(self, preds: Any, batch: Dict[str, torch.Tensor]) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Calculate and return the loss for oriented bounding box detection.\"\"\"\n",
    "        loss = torch.zeros(3, device=self.device)  # box, cls, dfl\n",
    "        feats, pred_angle = preds if isinstance(preds[0], list) else preds[1]\n",
    "        # batch size, number of masks, mask height, mask width\n",
    "        batch_size = pred_angle.shape[0]\n",
    "        pred_distri, pred_scores = torch.cat([xi.view(feats[0].shape[0], self.no, -1) for xi in feats], 2).split(\n",
    "            (self.reg_max * 4, self.nc), 1\n",
    "        )\n",
    "\n",
    "        # b, grids, ..\n",
    "        pred_scores = pred_scores.permute(0, 2, 1).contiguous()\n",
    "        pred_distri = pred_distri.permute(0, 2, 1).contiguous()\n",
    "        pred_angle = pred_angle.permute(0, 2, 1).contiguous()\n",
    "\n",
    "        dtype = pred_scores.dtype\n",
    "        imgsz = torch.tensor(feats[0].shape[2:], device=self.device,\n",
    "                             dtype=dtype) * self.stride[0]  # image size (h,w)\n",
    "        anchor_points, stride_tensor = make_anchors(feats, self.stride, 0.5)\n",
    "\n",
    "        # targets\n",
    "        try:\n",
    "            batch_idx = batch[\"batch_idx\"].view(-1, 1)\n",
    "            targets = torch.cat(\n",
    "                (batch_idx, batch[\"cls\"].view(-1, 1), batch[\"bboxes\"].view(-1, 5)), 1)\n",
    "            rw, rh = targets[:, 4] * \\\n",
    "                imgsz[0].item(), targets[:, 5] * imgsz[1].item()\n",
    "            # filter rboxes of tiny size to stabilize training\n",
    "            targets = targets[(rw >= 2) & (rh >= 2)]\n",
    "            targets = self.preprocess(targets.to(\n",
    "                self.device), batch_size, scale_tensor=imgsz[[1, 0, 1, 0]])\n",
    "            gt_labels, gt_bboxes = targets.split((1, 5), 2)  # cls, xywhr\n",
    "            mask_gt = gt_bboxes.sum(2, keepdim=True).gt_(0.0)\n",
    "        except RuntimeError as e:\n",
    "            raise TypeError(\n",
    "                \"ERROR ❌ OBB dataset incorrectly formatted or not a OBB dataset.\\n\"\n",
    "                \"This error can occur when incorrectly training a 'OBB' model on a 'detect' dataset, \"\n",
    "                \"i.e. 'yolo train model=yolo11n-obb.pt data=coco8.yaml'.\\nVerify your dataset is a \"\n",
    "                \"correctly formatted 'OBB' dataset using 'data=dota8.yaml' \"\n",
    "                \"as an example.\\nSee https://docs.ultralytics.com/datasets/obb/ for help.\"\n",
    "            ) from e\n",
    "\n",
    "        # Pboxes\n",
    "        pred_bboxes = self.bbox_decode(\n",
    "            anchor_points, pred_distri, pred_angle)  # xyxy, (b, h*w, 4)\n",
    "\n",
    "        bboxes_for_assigner = pred_bboxes.clone().detach()\n",
    "        # Only the first four elements need to be scaled\n",
    "        bboxes_for_assigner[..., :4] *= stride_tensor\n",
    "        _, target_bboxes, target_scores, fg_mask, _ = self.assigner(\n",
    "            pred_scores.detach().sigmoid(),\n",
    "            bboxes_for_assigner.type(gt_bboxes.dtype),\n",
    "            anchor_points * stride_tensor,\n",
    "            gt_labels,\n",
    "            gt_bboxes,\n",
    "            mask_gt,\n",
    "        )\n",
    "\n",
    "        target_scores_sum = max(target_scores.sum(), 1)\n",
    "\n",
    "        # Cls loss\n",
    "        # loss[1] = self.varifocal_loss(pred_scores, target_scores, target_labels) / target_scores_sum  # VFL way\n",
    "        loss[1] = self.bce(pred_scores, target_scores.to(\n",
    "            dtype)).sum() / target_scores_sum  # BCE\n",
    "\n",
    "        # Bbox loss\n",
    "        if fg_mask.sum():\n",
    "            target_bboxes[..., :4] /= stride_tensor\n",
    "            loss[0], loss[2] = self.bbox_loss(\n",
    "                pred_distri, pred_bboxes, anchor_points, target_bboxes, target_scores, target_scores_sum, fg_mask\n",
    "            )\n",
    "        else:\n",
    "            loss[0] += (pred_angle * 0).sum()\n",
    "\n",
    "        loss[0] *= self.hyp.box  # box gain\n",
    "        loss[1] *= self.hyp.cls  # cls gain\n",
    "        loss[2] *= self.hyp.dfl  # dfl gain\n",
    "\n",
    "        return loss * batch_size, loss.detach()  # loss(box, cls, dfl)\n",
    "\n",
    "    def bbox_decode(\n",
    "        self, anchor_points: torch.Tensor, pred_dist: torch.Tensor, pred_angle: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Decode predicted object bounding box coordinates from anchor points and distribution.\n",
    "\n",
    "        Args:\n",
    "            anchor_points (torch.Tensor): Anchor points, (h*w, 2).\n",
    "            pred_dist (torch.Tensor): Predicted rotated distance, (bs, h*w, 4).\n",
    "            pred_angle (torch.Tensor): Predicted angle, (bs, h*w, 1).\n",
    "\n",
    "        Returns:\n",
    "            (torch.Tensor): Predicted rotated bounding boxes with angles, (bs, h*w, 5).\n",
    "        \"\"\"\n",
    "        if self.use_dfl:\n",
    "            b, a, c = pred_dist.shape  # batch, anchors, channels\n",
    "            pred_dist = pred_dist.view(\n",
    "                b, a, 4, c // 4).softmax(3).matmul(self.proj.type(pred_dist.dtype))\n",
    "        return torch.cat((dist2rbox(pred_dist, pred_angle, anchor_points), pred_angle), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6df7829",
   "metadata": {},
   "outputs": [],
   "source": [
    "class v8OBBLoss(v8DetectionLoss):\n",
    "    \"\"\"计算旋转 YOLO 模型中的对象检测、分类和框分布的损失。\"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        \"\"\"使用模型、分配器和旋转的 bbox 损失初始化 v8OBBLoss；模型必须去并行化。\"\"\"\n",
    "        super().__init__(model)\n",
    "        self.assigner = RotatedTaskAlignedAssigner(\n",
    "            topk=10, num_classes=self.nc, alpha=0.5, beta=6.0)\n",
    "        self.bbox_loss = RotatedBboxLoss(self.reg_max).to(self.device)\n",
    "        self.angle_loss_fn = nn.SmoothL1Loss(\n",
    "            reduction=\"mean\").to(self.device)  # 平滑 L1 损失用于角度\n",
    "\n",
    "    def preprocess(self, targets: torch.Tensor, batch_size: int, scale_tensor: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"对定向边界框检测的目标进行预处理。\"\"\"\n",
    "        if targets.shape[0] == 0:\n",
    "            out = torch.zeros(batch_size, 0, 6, device=self.device)\n",
    "        else:\n",
    "            i = targets[:, 0]  # image index\n",
    "            _, counts = i.unique(return_counts=True)\n",
    "            counts = counts.to(dtype=torch.int32)\n",
    "            out = torch.zeros(batch_size, counts.max(), 6, device=self.device)\n",
    "            for j in range(batch_size):\n",
    "                matches = i == j\n",
    "                if n := matches.sum():\n",
    "                    bboxes = targets[matches, 2:]\n",
    "                    bboxes[..., :4].mul_(scale_tensor)\n",
    "                    out[j, :n] = torch.cat(\n",
    "                        [targets[matches, 1:2], bboxes], dim=-1)\n",
    "        return out\n",
    "\n",
    "    def __call__(self, preds: Any, batch: Dict[str, torch.Tensor]) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"计算并返回有向边界框检测的损失。\"\"\"\n",
    "        loss = torch.zeros(4, device=self.device)  # box, cls, dfl, rad\n",
    "        feats, pred_angle = preds if isinstance(preds[0], list) else preds[1]\n",
    "        # batch size, number of masks, mask height, mask width\n",
    "        batch_size = pred_angle.shape[0]\n",
    "        pred_distri, pred_scores = torch.cat([xi.view(feats[0].shape[0], self.no, -1) for xi in feats], 2).split(\n",
    "            (self.reg_max * 4, self.nc), 1\n",
    "        )\n",
    "\n",
    "        # b, grids, ..\n",
    "        pred_scores = pred_scores.permute(0, 2, 1).contiguous()\n",
    "        pred_distri = pred_distri.permute(0, 2, 1).contiguous()\n",
    "        pred_angle = pred_angle.permute(0, 2, 1).contiguous()\n",
    "\n",
    "        dtype = pred_scores.dtype\n",
    "        imgsz = torch.tensor(feats[0].shape[2:], device=self.device,\n",
    "                             dtype=dtype) * self.stride[0]  # image size (h,w)\n",
    "        anchor_points, stride_tensor = make_anchors(feats, self.stride, 0.5)\n",
    "\n",
    "        # targets\n",
    "        try:\n",
    "            batch_idx = batch[\"batch_idx\"].view(-1, 1)\n",
    "            targets = torch.cat(\n",
    "                (batch_idx, batch[\"cls\"].view(-1, 1), batch[\"bboxes\"].view(-1, 5)), 1)\n",
    "            rw, rh = targets[:, 4] * \\\n",
    "                imgsz[0].item(), targets[:, 5] * imgsz[1].item()\n",
    "            # filter rboxes of tiny size to stabilize training\n",
    "            targets = targets[(rw >= 2) & (rh >= 2)]\n",
    "            targets = self.preprocess(targets.to(\n",
    "                self.device), batch_size, scale_tensor=imgsz[[1, 0, 1, 0]])\n",
    "            gt_labels, gt_bboxes = targets.split((1, 5), 2)  # cls, xywhr\n",
    "            gt_angles = gt_bboxes[..., 4:5]\n",
    "            mask_gt = gt_bboxes.sum(2, keepdim=True).gt_(0.0)\n",
    "        except RuntimeError as e:\n",
    "            raise TypeError(\n",
    "                \"ERROR ❌ OBB dataset incorrectly formatted or not a OBB dataset.\\n\"\n",
    "                \"This error can occur when incorrectly training a 'OBB' model on a 'detect' dataset, \"\n",
    "                \"i.e. 'yolo train model=yolo11n-obb.pt data=coco8.yaml'.\\nVerify your dataset is a \"\n",
    "                \"correctly formatted 'OBB' dataset using 'data=dota8.yaml' \"\n",
    "                \"as an example.\\nSee https://docs.ultralytics.com/datasets/obb/ for help.\"\n",
    "            ) from e\n",
    "\n",
    "        # Pboxes\n",
    "        pred_bboxes = self.bbox_decode(\n",
    "            anchor_points, pred_distri, pred_angle)  # xyxy, (b, h*w, 4)\n",
    "\n",
    "        bboxes_for_assigner = pred_bboxes.clone().detach()\n",
    "        # Only the first four elements need to be scaled\n",
    "        bboxes_for_assigner[..., :4] *= stride_tensor\n",
    "        _, target_bboxes, target_scores, fg_mask, target_gt_idx = self.assigner(\n",
    "            pred_scores.detach().sigmoid(),\n",
    "            bboxes_for_assigner.type(gt_bboxes.dtype),\n",
    "            anchor_points * stride_tensor,\n",
    "            gt_labels,\n",
    "            gt_bboxes,\n",
    "            mask_gt,\n",
    "        )\n",
    "\n",
    "        target_scores_sum = max(target_scores.sum(), 1)\n",
    "\n",
    "        # Cls loss\n",
    "        # loss[1] = self.varifocal_loss(pred_scores, target_scores, target_labels) / target_scores_sum  # VFL way\n",
    "        loss[1] = self.bce(pred_scores, target_scores.to(\n",
    "            dtype)).sum() / target_scores_sum  # BCE\n",
    "\n",
    "        # Bbox loss\n",
    "        if fg_mask.sum():\n",
    "            target_bboxes[..., :4] /= stride_tensor\n",
    "            loss[0], loss[2] = self.bbox_loss(\n",
    "                pred_distri, pred_bboxes, anchor_points, target_bboxes, target_scores, target_scores_sum, fg_mask\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            loss[0] += (pred_angle * 0).sum()\n",
    "\n",
    "        # Angle loss\n",
    "        target_angles = self._get_target_angles(\n",
    "            gt_angles, target_gt_idx, fg_mask)\n",
    "        loss[3] = self.angle_loss(\n",
    "            pred_angle, target_angles, fg_mask, target_scores_sum)\n",
    "\n",
    "        # 各损失的权重\n",
    "        loss[0] *= self.hyp.box  # box gain\n",
    "        loss[1] *= self.hyp.cls  # cls gain\n",
    "        loss[2] *= self.hyp.dfl  # dfl gain\n",
    "        loss[3] *= getattr(self.hyp, \"rad\", 1.0)  # rad gain\n",
    "\n",
    "        return loss * batch_size, loss.detach()  # loss(box, cls, dfl)\n",
    "\n",
    "    def bbox_decode(\n",
    "        self, anchor_points: torch.Tensor, pred_dist: torch.Tensor, pred_angle: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Decode predicted object bounding box coordinates from anchor points and distribution.\n",
    "\n",
    "        从锚点和分布解码预测的对象边界框坐标。\n",
    "\n",
    "        Args:\n",
    "            anchor_points (torch.Tensor): Anchor points, (h*w, 2).\n",
    "            pred_dist (torch.Tensor): Predicted rotated distance, (bs, h*w, 4).\n",
    "            pred_angle (torch.Tensor): Predicted angle, (bs, h*w, 1).\n",
    "\n",
    "        Returns:\n",
    "            (torch.Tensor): Predicted rotated bounding boxes with angles, (bs, h*w, 5).\n",
    "        \"\"\"\n",
    "        if self.use_dfl:\n",
    "            b, a, c = pred_dist.shape  # batch, anchors, channels\n",
    "            pred_dist = pred_dist.view(\n",
    "                b, a, 4, c // 4).softmax(3).matmul(self.proj.type(pred_dist.dtype))\n",
    "        return torch.cat((dist2rbox(pred_dist, pred_angle, anchor_points), pred_angle), dim=-1)\n",
    "\n",
    "    def _get_target_angles(self, gt_angles: torch.Tensor, target_gt_idx: torch.Tensor, fg_mask: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"根据分配结果获取目标角度\"\"\"\n",
    "        batch_size = gt_angles.shape[0]\n",
    "        target_angles = torch.zeros_like(\n",
    "            target_gt_idx, dtype=gt_angles.dtype, device=gt_angles.device)\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            if fg_mask[b].sum() > 0:\n",
    "                valid_idx = target_gt_idx[b][fg_mask[b]]\n",
    "                target_angles[b][fg_mask[b]] = gt_angles[b, valid_idx, 0]\n",
    "\n",
    "        return target_angles\n",
    "\n",
    "    def angle_loss(self, pred_angle: torch.Tensor, target_angle: torch.Tensor, fg_mask: torch.Tensor, target_scores_sum: float) -> torch.Tensor:\n",
    "        \"\"\"计算角度损失，考虑角度的周期性\"\"\"\n",
    "        if fg_mask.sum() == 0:\n",
    "            return torch.tensor(0.0, device=pred_angle.device)\n",
    "\n",
    "        # 提取前景区域的角度\n",
    "        pred_fg = pred_angle[fg_mask]\n",
    "        target_fg = target_angle[fg_mask]\n",
    "\n",
    "        # 计算角度差异，考虑周期性 [-π, π]\n",
    "        diff = pred_fg - target_fg\n",
    "        diff = torch.atan2(torch.sin(diff), torch.cos(diff))  # 将差异规范化到 [-π, π]\n",
    "\n",
    "        # 使用平滑L1损失或MSE损失\n",
    "        angle_loss = self.angle_loss_fn(diff, torch.zeros_like(diff))\n",
    "\n",
    "        return angle_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "screw-dett",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
